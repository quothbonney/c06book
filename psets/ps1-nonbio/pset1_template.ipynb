{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quothbonney/c06book/blob/master/psets/ps1-nonbio/pset1_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e034b987-1165-4d11-9bc9-bd7885305ced",
      "metadata": {
        "id": "e034b987-1165-4d11-9bc9-bd7885305ced"
      },
      "source": [
        "#  <center> Problem Set 1 (Perovskites) <center>\n",
        "<center> Spring 2025 <center>\n",
        "<center> 3.C01/3.C51, 7.C01/7.C51, 10.C01/10.C51, 20.C01/20.C51 <center>\n",
        "<center> Due: Monday, April 7, 2025 at 3:00 PM ET. <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889a8585-0908-448d-8b47-3f3c3abaa46e",
      "metadata": {
        "id": "889a8585-0908-448d-8b47-3f3c3abaa46e"
      },
      "source": [
        "<b>Name:</b>\n",
        "\n",
        "<b>Kerberos ID:</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fdb70c-3eee-46de-b405-f40da05f290a",
      "metadata": {
        "id": "e7fdb70c-3eee-46de-b405-f40da05f290a"
      },
      "source": [
        "### Instructions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646b9b98-edf7-4017-b00d-7b09302cab09",
      "metadata": {
        "id": "646b9b98-edf7-4017-b00d-7b09302cab09"
      },
      "source": [
        "Put your code in the code blocks flagged with `############# Code ##########`.\n",
        "\n",
        "Numerical answers yielded from running the code should be included in an Answer Block (see next cell).\n",
        "\n",
        "We have provided print statements where numerical answers are expected.\n",
        "\n",
        "Your answer should be contained in a variable which you defined either in the Answer Block or the Code Block.\n",
        "\n",
        "When a qualitative answer is expected, place those comments as Markdown/Text cells; when asked for within Code blocks, you can write answer as code comments by placing a # before your answer.\n",
        "\n",
        "Your Answer Block should look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c05dc04-777e-45c4-b826-54f8ec206b3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c05dc04-777e-45c4-b826-54f8ec206b3e",
        "outputId": "a4d7368c-98fb-41ee-db5d-96aa4f4046e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My answer is: 2.\n"
          ]
        }
      ],
      "source": [
        "########## Answer ############\n",
        "\n",
        "ans = 2\n",
        "print(\"My answer is: {}.\".format(ans))\n",
        "\n",
        "# My regressor over-fitted the training data, I need to add regularization\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ddc72ba-4909-43b0-81f8-64fbc889ac5e",
      "metadata": {
        "id": "9ddc72ba-4909-43b0-81f8-64fbc889ac5e"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c3c249-5923-420d-a1af-d8978eeb7135",
      "metadata": {
        "id": "52c3c249-5923-420d-a1af-d8978eeb7135"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import preprocessing\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# plotting style, you can choose your own parameters\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 15})\n",
        "matplotlib.rc('lines', linewidth=3, color='g')\n",
        "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
        "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
        "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
        "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
        "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
        "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
        "matplotlib.rcParams['text.usetex'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_TBwUjROsxuL",
      "metadata": {
        "id": "_TBwUjROsxuL"
      },
      "outputs": [],
      "source": [
        "# A helper function for students to produce plots\n",
        "def plot_clf(model, X, y, title):\n",
        "\n",
        "    '''\n",
        "        A function to plot confusion matrix and ROC curve\n",
        "\n",
        "        Args:\n",
        "            model(classifier object): model object (e.g. RandomForestClassifier, LogisticRegression)\n",
        "            X(np.array): feature set\n",
        "            y(np.array): label set\n",
        "            title(str): plot name\n",
        "\n",
        "        Example Usage:\n",
        "            plot_clf(model, X_test, y_test, \"test\")\n",
        "    '''\n",
        "\n",
        "    fig, [ax_roc, ax_conf] = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    RocCurveDisplay.from_estimator(model, X, y, ax=ax_roc)\n",
        "    ConfusionMatrixDisplay.from_estimator(model, X, y, ax=ax_conf)\n",
        "\n",
        "    ax_roc.set_title('{} ROC'.format(title))\n",
        "    ax_conf.set_title('{} Confusion Matrix'.format(title))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa19014-1a8e-4dd3-9d5e-62757bd2ddef",
      "metadata": {
        "id": "2aa19014-1a8e-4dd3-9d5e-62757bd2ddef"
      },
      "source": [
        "## Grading guideline\n",
        "\n",
        "- Didn't answer the question 0%\n",
        "- Showed some attempts, but clearly didn't try enough: 25%\n",
        "- Showed solid attempts (showed code) but does not answer the question directly: 50%\n",
        "- Showed solid attempts and get the question wrong: 60-80%\n",
        "- Showed solid attempts with some small mistakes: 80-90%\n",
        "- Showed code and answered the questions correctly: 100%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c520134-603d-4b09-b1ad-4d41c29543a0",
      "metadata": {
        "id": "9c520134-603d-4b09-b1ad-4d41c29543a0"
      },
      "source": [
        "# Overview:\n",
        "In this PSET, you will:\n",
        "\n",
        "* Learn the basics of processing your data and training a machine learning model with PyTorch:\n",
        "    * Processing data, including exploring OHE vs. other featurization techniques\n",
        "    * Formatting your data into a `Dataset` object and wrapping in a `DataLoader` instance\n",
        "    * Implementation of a Multi-Layer Perception in `PyTorch`\n",
        "    * Setting up a training and testing loop, and how to do evaluation\n",
        "    * Using a GPU to accelerate training!\n",
        "    * Find the best hyperparameters\n",
        "\n",
        "\n",
        "* Learn how to build some simple architectures for **classification** and **regression**:\n",
        "    * Train a logistic regression model with `scikit-learn` to _classify_ breast cancers based on metabolite abundance\n",
        "    *  Train a random forest classifier on the same data\n",
        "    * Train a MLP using `PyTorch` on the same data\n",
        "    * Train a MLP with `PyTorch` to _regress_ perovskite hull energies from their compositions\n",
        "    * Apply regularization techniques to avoid overfitting (L1 and L2)\n",
        "    * Apply physical descriptor-based encoding to improve training performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afcbf779-72b9-45c7-85a2-3a87abda2a25",
      "metadata": {
        "id": "afcbf779-72b9-45c7-85a2-3a87abda2a25"
      },
      "source": [
        "## Download required data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3657070-bafe-4ef6-a5f4-1d8f94694976",
      "metadata": {
        "id": "a3657070-bafe-4ef6-a5f4-1d8f94694976",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# for 1st set of tasks: binary classification\n",
        "# TODO: update the datapaths\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/breastcancer_X.csv\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/breastcancer_y.csv\n",
        "\n",
        "# for 2nd set of tasks: regression of perovskite binding energies\n",
        "\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/data_perov/mendeleev.csv\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/data_perov/perov_train.csv\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/data_perov/perov_val.csv\n",
        "! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps1-nonbio/data/data_perov/elements.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73d3fff-9246-4bf8-8837-f41287abcec4",
      "metadata": {
        "id": "e73d3fff-9246-4bf8-8837-f41287abcec4"
      },
      "source": [
        "# Problem 1: Breast cancer classification from metabolite data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db76fddc-7695-44c0-8aad-90dd9fba5260",
      "metadata": {
        "id": "db76fddc-7695-44c0-8aad-90dd9fba5260"
      },
      "source": [
        "## 1.1 (5 points) Load and inspect the raw data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1fbe02-f0bd-41aa-8360-4a4074da6299",
      "metadata": {
        "id": "2b1fbe02-f0bd-41aa-8360-4a4074da6299"
      },
      "source": [
        "We have provided the code to load the dataset. Take a moment to understand what each line is doing. Briefly explain what each line of the code is doing by providing short comments below.\n",
        "\n",
        "You will have to do it by yourself again in Problem 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "271cfcec-a74a-4c82-aa00-4142277e7544",
      "metadata": {
        "id": "271cfcec-a74a-4c82-aa00-4142277e7544"
      },
      "outputs": [],
      "source": [
        "p1_X = pd.read_csv(\"./breastcancer_X.csv\", header='infer', index_col=0) # Comments here\n",
        "p1_y = pd.read_csv(\"./breastcancer_y.csv\", header='infer', index_col=0) # Comments here\n",
        "\n",
        "metabolite_name = p1_X.columns.tolist() # Comments here\n",
        "\n",
        "p1_X = p1_X.values # Comments here\n",
        "p1_y = p1_y.values # Comments here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0badc9a8-3ab1-4d57-8087-bccc091b499c",
      "metadata": {
        "id": "0badc9a8-3ab1-4d57-8087-bccc091b499c"
      },
      "source": [
        "Report how many examples are in this dataset and the number of features for each data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AqSUO0dQqelF",
      "metadata": {
        "id": "AqSUO0dQqelF"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "print(\"There are {} samples.\".format(N_samples))\n",
        "print(\"There are {} features per sample.\".format(N_features))\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03905895-b495-44af-bbd9-84b087d7c14a",
      "metadata": {
        "id": "03905895-b495-44af-bbd9-84b087d7c14a"
      },
      "source": [
        "## 1.2 (5 points) Generate train/test splits.\n",
        "Generate and print the shapes of your four variables, `X_train`, `X_test`, `y_train`, and `y_test`, and ensure sure that the dimensions match your expectations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LTgamc0MrENZ",
      "metadata": {
        "id": "LTgamc0MrENZ"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r4--K6NFrOwt",
      "metadata": {
        "id": "r4--K6NFrOwt"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "X_train_shape = X_train.shape\n",
        "y_train_shape = y_train.shape\n",
        "X_test_shape = X_test.shape\n",
        "y_test_shape = y_test.shape\n",
        "\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train_shape))\n",
        "print(\"y_train shape: {}\".format(y_train_shape))\n",
        "\n",
        "print(\"X_test shape: {}\".format(X_test_shape))\n",
        "print(\"y_test shape: {}\".format(y_test_shape))\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1698fec-0e99-4732-b0d9-02781a634f40",
      "metadata": {
        "id": "d1698fec-0e99-4732-b0d9-02781a634f40"
      },
      "source": [
        "## 1.3 (5 points) Preprocess the data through scaling\n",
        "Scale the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sXU5xW6sqoR6",
      "metadata": {
        "id": "sXU5xW6sqoR6"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975a1070-4c6d-4cf8-878f-a4f5d35ce8b2",
      "metadata": {
        "id": "975a1070-4c6d-4cf8-878f-a4f5d35ce8b2"
      },
      "source": [
        "Print the mean/variance for each transformed feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BH_8w9bnqoPV",
      "metadata": {
        "id": "BH_8w9bnqoPV"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "train_mean = X_train_scaled.mean(0)\n",
        "train_variance = X_train_scaled.std(0) ** 2\n",
        "\n",
        "test_mean = X_test_scaled.mean(0)\n",
        "test_variance = X_test_scaled.std(0) ** 2\n",
        "\n",
        "print(\"The means of the transformed feature train set are {}\".format(train_mean))\n",
        "print(\"The variances of the transformed feature train set are {}\".format(train_variance))\n",
        "print(\"The means of the transformed feature test set are {}\".format(test_mean))\n",
        "print(\"The variances of the transformed feature test set are {}\".format(test_variance))\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec60db5-1093-4209-936f-cce5890d89c3",
      "metadata": {
        "id": "7ec60db5-1093-4209-936f-cce5890d89c3"
      },
      "source": [
        "\n",
        "Q: Discuss the importance of not fitting the scaler transform on both train & test; why the transformed mean / variance between X_test_scaled & X_train_scaled may not be the same; and why this difference is potentially heartening."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76bceda3-8081-447e-8084-7c452e250ad9",
      "metadata": {
        "id": "76bceda3-8081-447e-8084-7c452e250ad9"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14036ca0-9b27-443c-8e8f-0d3344bd1635",
      "metadata": {
        "id": "14036ca0-9b27-443c-8e8f-0d3344bd1635"
      },
      "source": [
        "## 1.4 (10 points) Training a logistic regression classifier with `scikit-learn`\n",
        "\n",
        "`scikit-learn` has many handy simple machine learning frameworks that make it relatively simple to train, cross-validate, and tune a machine learning model that does not need to be heavily customized.\n",
        "\n",
        "\n",
        "Below, train and evaluate a Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pdcr-vW6r1Ny",
      "metadata": {
        "id": "Pdcr-vW6r1Ny"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dabe4ef-08ca-42c9-ba0f-2d8083cb70d7",
      "metadata": {
        "id": "2dabe4ef-08ca-42c9-ba0f-2d8083cb70d7"
      },
      "source": [
        "Report the AUC for both the train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N-ymurzWr1J6",
      "metadata": {
        "id": "N-ymurzWr1J6"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "print(\"The training AUC score is {:.3f}\".format(train_auc) )\n",
        "print(\"The testing AUC score is {:.3f}\".format(test_auc) )\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5639b36-6eeb-490d-9cce-0ba8bd596c97",
      "metadata": {
        "id": "d5639b36-6eeb-490d-9cce-0ba8bd596c97"
      },
      "source": [
        "Generate plots for the confusion matrices and the ROC curve for both training and testing. Please use the `plot_clf` function defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kmX6w9z0r1Fd",
      "metadata": {
        "id": "kmX6w9z0r1Fd"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4404494c-45cf-418d-8ad5-d964558c0e09",
      "metadata": {
        "id": "4404494c-45cf-418d-8ad5-d964558c0e09"
      },
      "source": [
        "Generate a plot of the model coefficients' distribution using `plt.hist`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AFRbzxjbx1VF",
      "metadata": {
        "id": "AFRbzxjbx1VF"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f7f4d14-ead5-4bd9-a813-3d1abe3bc559",
      "metadata": {
        "id": "2f7f4d14-ead5-4bd9-a813-3d1abe3bc559"
      },
      "source": [
        "## 1.5 (5 points) Introduce L1 regularization\n",
        "Modify the LogisticRegression call made to run L1-regularized logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9XkbYnKWudTY",
      "metadata": {
        "id": "9XkbYnKWudTY"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549cb3fe-f2e4-4f57-a344-f6ecedec09a1",
      "metadata": {
        "id": "549cb3fe-f2e4-4f57-a344-f6ecedec09a1"
      },
      "source": [
        "Report the ROC-AUC score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "px0mWfuCuYQe",
      "metadata": {
        "id": "px0mWfuCuYQe"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "\n",
        "print(\"The training AUC score is {:.2f}\".format(train_auc) )\n",
        "print(\"The testing AUC score is {:.2f}\".format(test_auc) )\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9397c864-ab51-4ab6-adbc-93a0a50a2a0b",
      "metadata": {
        "id": "9397c864-ab51-4ab6-adbc-93a0a50a2a0b"
      },
      "source": [
        "Correspondingly, generate the new confusion matrix and ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OtFraBevv18P",
      "metadata": {
        "id": "OtFraBevv18P"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4d9430-2761-4c7b-89b7-159b287b280d",
      "metadata": {
        "id": "ab4d9430-2761-4c7b-89b7-159b287b280d"
      },
      "source": [
        "Plot the new distribution of model coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-x6wv4HcxszS",
      "metadata": {
        "id": "-x6wv4HcxszS"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72066f0c-df3e-4d8a-b494-90363a76a499",
      "metadata": {
        "id": "72066f0c-df3e-4d8a-b494-90363a76a499"
      },
      "source": [
        "Comment on the histogram you obtained, by comparing it to the one generated from the unregularized model's coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad8ec442-27fa-4f37-a044-c0d6462236b6",
      "metadata": {
        "id": "ad8ec442-27fa-4f37-a044-c0d6462236b6"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f83cfa-e3c8-4e0c-bcee-b9eac22ee597",
      "metadata": {
        "id": "a3f83cfa-e3c8-4e0c-bcee-b9eac22ee597"
      },
      "source": [
        "## 1.6  (optional +2.5 points) Connect model coefficients back to metabolites"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41c63d16-4452-4146-918b-443aee099b20",
      "metadata": {
        "id": "41c63d16-4452-4146-918b-443aee099b20"
      },
      "source": [
        "Code to identify the top 5 metabolites that positively correlated the most with positive diagnosis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28800ebd-7848-440c-966d-912b363c7222",
      "metadata": {
        "id": "28800ebd-7848-440c-966d-912b363c7222"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3b73f9-f147-404a-9bb8-c0d343f7d05e",
      "metadata": {
        "id": "0f3b73f9-f147-404a-9bb8-c0d343f7d05e"
      },
      "source": [
        "Report the metabolites you identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be305a4-21d4-48bb-ab72-b065955f0f95",
      "metadata": {
        "id": "3be305a4-21d4-48bb-ab72-b065955f0f95"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "print(\"The top 5 metabolites are {}\".format(\", \".join(metabolites)) )\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1229ab8-6864-458e-80a9-32ef93b93b2e",
      "metadata": {
        "id": "d1229ab8-6864-458e-80a9-32ef93b93b2e"
      },
      "source": [
        "## 1.7 (5 points) Hyperparameter tuning the regularization parameter\n",
        "Scan over the following regularization values `C=[0.01, 1, 5, 10]` (in `scikit-learn`, the regularization parameter `C` is inversely related to the regularization strength) and report which one yields the best performance (with the AUROC metric) on the train dataset. What is its performance on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9f2613-8363-4a01-a216-fe7155bbd2ba",
      "metadata": {
        "id": "4f9f2613-8363-4a01-a216-fe7155bbd2ba"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "best_value = None\n",
        "best_metric = 0\n",
        "C_values = [0.01, 1, 5, 10]\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3c7868-6073-4c72-a196-8de05e5222f5",
      "metadata": {
        "id": "2b3c7868-6073-4c72-a196-8de05e5222f5"
      },
      "outputs": [],
      "source": [
        "########### Answer #############\n",
        "\n",
        "print(f\"Best value: C = {best_value}\")\n",
        "# Performance on test AUC:\n",
        "print(\"The hyperparameterized model's test AUC score is {:.2f}\".format(test_auc) )\n",
        "\n",
        "########### Answer #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e737ffa-5823-4145-86ca-1547df99ab79",
      "metadata": {
        "id": "9e737ffa-5823-4145-86ca-1547df99ab79"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4cddd8d-e562-4757-b97a-79575e01950e",
      "metadata": {
        "id": "b4cddd8d-e562-4757-b97a-79575e01950e"
      },
      "source": [
        "## 1.8 (5 points) Training a random forest classifier with `scikit-learn`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dab30c2-7676-4154-ab8c-b9148da8bb93",
      "metadata": {
        "id": "8dab30c2-7676-4154-ab8c-b9148da8bb93"
      },
      "source": [
        "To minimize the variance of our method to reduce error arising from epistemic error (that is, from a set of limited data), we may often look to train multiple copies of a machine learning model, i.e., an _ensemble_ machine learning method.\n",
        "\n",
        "Here, train a Random Forest classifier, which is an ensemble of decision trees. Random Forests, empirically, work really well on tabular data, but can be known to overfit easily. To mitigate this concern, also perform cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b501af0-ed32-4070-a49e-e2294b6e7dde",
      "metadata": {
        "id": "3b501af0-ed32-4070-a49e-e2294b6e7dde"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "scaler = # fill this in (reusing your scaler implementation from 1.3)\n",
        "model = # fill this in\n",
        "pipeline = Pipeline([('scaler', scaler), ('model', model)])\n",
        "\n",
        "# Now call cross_val_score() and feed it: your pipeline as the estimator\n",
        "# and your data (p1_X & p1_y) letting cross_val_score() handle the test / train split for you.\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c1d6b6-49fc-47ba-b2bc-2f08804e7c80",
      "metadata": {
        "id": "71c1d6b6-49fc-47ba-b2bc-2f08804e7c80"
      },
      "source": [
        "Report the cross-validated ROC-AUC score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8956d06d-2174-4390-b7bf-7d2751d44390",
      "metadata": {
        "id": "8956d06d-2174-4390-b7bf-7d2751d44390"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "\n",
        "print(\"The mean of CV scores is {:.2f}\".format(mean) )\n",
        "print(\"The std of CV scores is {:.2f}\".format(std) )\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cNuI7Bu7zusk",
      "metadata": {
        "id": "cNuI7Bu7zusk"
      },
      "source": [
        "# Problem 2: Training a Multi-Layer Perceptron (MLP) to predict perovskite energies\n",
        "## 2.1: (5 points) Encoding the data\n",
        "\n",
        "For this second task, we will utilize perovskite data to predict their $E_{hull}$ values. Before we can build a model, we need to process the data by one-hot encoding the perovskites based on their elements.\n",
        "\n",
        "Generate the X matrix and y vector from processing `perov_train` and `perov_test` appropriately (do not run any inference on `perov_test` until Part 2.5, but it's helpful to process it the same way here for consistency). Hint: Note that the one-hot encoding we perform should still give us a 2D matrix of `n_samples` x `n_features`, but now `n_features` will be different from the number of features originally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oDBpvmLY0tMl",
      "metadata": {
        "id": "oDBpvmLY0tMl"
      },
      "outputs": [],
      "source": [
        "perov_train = pd.read_csv(\"perov_train.csv\") # read train\n",
        "perov_test = pd.read_csv(\"perov_val.csv\") # read test\n",
        "all_elements = np.load('./elements.npy', allow_pickle=True) # Read all elements\n",
        "\n",
        "\n",
        "# Your code to featurize elements\n",
        "########### Code #############\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LMDWki271wil",
      "metadata": {
        "id": "LMDWki271wil"
      },
      "source": [
        "Report the number of samples, number of features, and the number of possible values for one (not yet one-hot-encoded) feature you might have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00aedf37-642f-4173-8ec9-4af613ce0b8e",
      "metadata": {
        "id": "00aedf37-642f-4173-8ec9-4af613ce0b8e"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "print(\"There are {} samples.\".format(N_samples))\n",
        "print(\"There are {} features per sample.\".format(N_features))\n",
        "print(\"There are {} possible values for one feature.\".format(N_feat_vals))\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a64FEr159O7",
      "metadata": {
        "id": "8a64FEr159O7"
      },
      "source": [
        "## Check GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123e82a4-b7e2-40ff-b13d-5860bd95f1cb",
      "metadata": {
        "id": "123e82a4-b7e2-40ff-b13d-5860bd95f1cb"
      },
      "outputs": [],
      "source": [
        "# Check if your GPU is requested successfully or not\n",
        "assert torch.cuda.device_count() != 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6496d2db-b29a-4920-857b-eaec8ce1e2d0",
      "metadata": {
        "id": "6496d2db-b29a-4920-857b-eaec8ce1e2d0"
      },
      "source": [
        "To work with GPU-accelerated training, we need to use `PyTorch`'s `Tensor` objects, which can help us manage CPU vs. GPU usage.\n",
        "\n",
        "Demonstrate moving this sample tensor to and from the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c18a349-0321-4018-9326-c801553fddb1",
      "metadata": {
        "id": "6c18a349-0321-4018-9326-c801553fddb1"
      },
      "outputs": [],
      "source": [
        "numpy_sample = np.zeros((3, 5))\n",
        "tensor_sample = torch.Tensor(numpy_sample)\n",
        "print(tensor_sample.device)\n",
        "\n",
        "###\n",
        "tensor_sample = tensor_sample.to('cuda')\n",
        "print(tensor_sample.device)\n",
        "tensor_sample = tensor_sample.to('cpu')\n",
        "print(tensor_sample.device)\n",
        "\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd58ef8-2bac-485a-a284-c7c649c22817",
      "metadata": {
        "id": "4dd58ef8-2bac-485a-a284-c7c649c22817"
      },
      "source": [
        "## Build Datasets and DataLoaders in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598be67c-4df0-4f18-a12c-6d8de125fc99",
      "metadata": {
        "id": "598be67c-4df0-4f18-a12c-6d8de125fc99"
      },
      "source": [
        "Below, we provide you with an example of a `Dataset` instance, the `SequenceDataset` class, to format your data.\n",
        "\n",
        "Note that tensors are not moved onto the GPU at initialization or inside `__getitem__`; GPU memory is typically far more limited than CPU-available memory. To prevent out-of-memory errors, we typically minimize the amount of data on the GPU at any time. During `.forward()`, the easiest way to do this is by only putting one batch at a time on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bfa1a9-ec4d-4206-ae38-f02f94b596fe",
      "metadata": {
        "id": "23bfa1a9-ec4d-4206-ae38-f02f94b596fe"
      },
      "outputs": [],
      "source": [
        "# Generate dataset\n",
        "class PerovskiteDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.Tensor(np.array(X))  # store X as a pytorch Tensor\n",
        "        self.y = torch.Tensor(np.array(y))  # store y as a pytorch Tensor\n",
        "        self.len=len(self.X)                # number of samples in the data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index] # get the appropriate item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f6898b-3caf-455b-9346-0bde14696988",
      "metadata": {
        "id": "d4f6898b-3caf-455b-9346-0bde14696988"
      },
      "source": [
        "Use the above `Dataset` object to make train, validation, and test `PervoskiteDataset` objects, then wrap each in a `DataLoader` object. Here are some handy arguments you can use to tweak the DataLoader object:\n",
        "* `batch_size`: the number of examples that your model will see during one forward/backward call.\n",
        "* `shuffle`: whether or not to shuffle your data between epochs; if it is set to True, then each epoch's batches will be different in identity.\n",
        "* `num_workers`: useful for when you have a lot of data to load in when making a batch; this allows you to multiprocess batch formation before they are used in forward calls on the GPU. it won't make much difference in this homework, but can be handy down the line :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "62b94588-1890-448c-8f9a-63e60103ca3a",
      "metadata": {
        "id": "62b94588-1890-448c-8f9a-63e60103ca3a"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "X_subtrain, X_val, y_subtrain, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "train_data = PerovskiteDataset(X_subtrain, y_subtrain)\n",
        "val_data = PerovskiteDataset(X_val, y_val)\n",
        "test_data = PerovskiteDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b3156d-6061-4f9a-9ab7-96ca25d84488",
      "metadata": {
        "id": "99b3156d-6061-4f9a-9ab7-96ca25d84488"
      },
      "source": [
        "Run this cell to check that your DataLoaders work as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "91504533-2a76-4a52-a561-37b6e2a7d71f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91504533-2a76-4a52-a561-37b6e2a7d71f",
        "outputId": "9ca2eb67-fac2-4796-d3dd-f19197b9f1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([100, 136]) torch.Size([100])\n",
            "\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([90, 136]) torch.Size([90])\n",
            "\n",
            "torch.Size([128, 136]) torch.Size([128])\n",
            "torch.Size([82, 136]) torch.Size([82])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "########### Code #############\n",
        "\n",
        "for loader in [train_dataloader, val_dataloader, test_dataloader]:\n",
        "    for index, batch in enumerate(loader):\n",
        "        # Your batch returns a X, y stacked in a batch\n",
        "        X_batch, y_batch = batch[0], batch[1]\n",
        "        print(X_batch.shape, y_batch.shape)\n",
        "    print()\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3389c2f4-2481-4a57-89c7-4d2db4d88775",
      "metadata": {
        "id": "3389c2f4-2481-4a57-89c7-4d2db4d88775"
      },
      "source": [
        "There should be 11 training set batches, 3 validation batches, and 2 test batches, with sizes shown above. Each set has an final, impartial batch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d48b4ccf-2fba-42d0-901e-514484fcf680",
      "metadata": {
        "id": "d48b4ccf-2fba-42d0-901e-514484fcf680"
      },
      "source": [
        "## 2.2 (10 points) Define the MLP in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c0f329-6973-4c1d-8d79-d7c8b3374bdd",
      "metadata": {
        "id": "10c0f329-6973-4c1d-8d79-d7c8b3374bdd"
      },
      "source": [
        "Look at the following code snippet to understand how the linear layer works in PyTorch. Take careful note of the dimensions of the input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "6ee9912d-db20-4bef-aace-0162b82f7f9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee9912d-db20-4bef-aace-0162b82f7f9f",
        "outputId": "81d16fe7-0205-40cd-d268-b543fae403ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) tensor([[ 0.3321, -0.3318,  0.5806],\n",
            "        [ 0.3321, -0.3318,  0.5806],\n",
            "        [ 0.3321, -0.3318,  0.5806],\n",
            "        [ 0.3321, -0.3318,  0.5806]], grad_fn=<AddmmBackward0>) torch.Size([4, 2]) torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "linear = torch.nn.Linear(2, 3)\n",
        "\n",
        "input_tensor = torch.ones((4, 2))\n",
        "output_tensor = linear(input_tensor)\n",
        "\n",
        "print(input_tensor, output_tensor, input_tensor.shape, output_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2639067-a2f4-46c4-b782-c21125a7f3c3",
      "metadata": {
        "id": "b2639067-a2f4-46c4-b782-c21125a7f3c3"
      },
      "source": [
        "Look at the following code snippet to understand how the ReLU layer works in PyTorch (the Tanh layer is similar). Take careful note of the dimensions of the input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "b08e9592-b37d-4985-a88d-14e7dcce2cb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b08e9592-b37d-4985-a88d-14e7dcce2cb8",
        "outputId": "72fbdd0f-8993-4403-9ed1-69e32d557245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) torch.Size([4, 2]) torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "relu = torch.nn.ReLU()\n",
        "\n",
        "input_tensor = torch.ones((4, 2))\n",
        "output_tensor = relu(input_tensor)\n",
        "\n",
        "print(input_tensor, output_tensor, input_tensor.shape, output_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e80fd7-dacb-4211-a1d9-05582ddaeb7c",
      "metadata": {
        "id": "84e80fd7-dacb-4211-a1d9-05582ddaeb7c"
      },
      "source": [
        "Look at the following code snippet to understand how to stack layers with the Sequential module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "d7de640c-b4b9-446f-b792-d9ef53033281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7de640c-b4b9-446f-b792-d9ef53033281",
        "outputId": "2b1a9647-b5bf-43f7-c0f3-d55b9d44d7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) tensor([[ 0.2243,  0.3194,  0.7627, -0.2021],\n",
            "        [ 0.2243,  0.3194,  0.7627, -0.2021],\n",
            "        [ 0.2243,  0.3194,  0.7627, -0.2021],\n",
            "        [ 0.2243,  0.3194,  0.7627, -0.2021],\n",
            "        [ 0.2243,  0.3194,  0.7627, -0.2021]], grad_fn=<AddmmBackward0>) torch.Size([5, 2]) torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "layer1 = torch.nn.Linear(2, 3)\n",
        "layer2 = torch.nn.Linear(3, 4)\n",
        "\n",
        "sequential = torch.nn.Sequential(layer1, layer2)\n",
        "\n",
        "input_tensor = torch.ones((5, 2))\n",
        "output_tensor = sequential(input_tensor)\n",
        "\n",
        "print(input_tensor, output_tensor, input_tensor.shape, output_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4b0ded-5b41-4126-afb1-09ddc1bf9ce3",
      "metadata": {
        "id": "ae4b0ded-5b41-4126-afb1-09ddc1bf9ce3"
      },
      "source": [
        "Build your MLP within the following torch.nn.Module object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "d5dfbba0-ab50-4ec8-96fa-3ca23ed9bd73",
      "metadata": {
        "id": "d5dfbba0-ab50-4ec8-96fa-3ca23ed9bd73"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "class PerovMLP(torch.nn.Module):\n",
        "    def __init__(self, in_features=136, hidden_dim=256, layers=3, activation=nn.ReLU()):\n",
        "        # You may either modify the above __init__ call to either take in hyperparameters as keyword arguments,\n",
        "        # or hard-code them below. If you want to do hyperparameter search, then modifying to take in\n",
        "        # keyword arguments is recommended.\n",
        "        super().__init__()\n",
        "        ########### Code #############\n",
        "\n",
        "        # Implement your code here\n",
        "        self.layers = []\n",
        "        self.layers.append(nn.Linear(in_features, hidden_dim))\n",
        "        self.layers.append(activation)\n",
        "\n",
        "        for _ in range(layers - 1):\n",
        "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.layers.append(activation)\n",
        "\n",
        "        self.layers.append(nn.Linear(hidden_dim, 1)) # output is 1d scalars\n",
        "\n",
        "        self.model = nn.Sequential(*layers) # this is so extra i was so confused for a second.\n",
        "        # also needlessly memory intensive since we are persisting basically two copies. torch might optimize this idk\n",
        "        ########### Code #############\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdf438c5-183d-46aa-9507-4169de131f20",
      "metadata": {
        "id": "cdf438c5-183d-46aa-9507-4169de131f20"
      },
      "source": [
        "## 2.3 (10 points) Implement functions for training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcf7e7b-b3ec-4386-a6f8-aa67ec7324b5",
      "metadata": {
        "id": "8bcf7e7b-b3ec-4386-a6f8-aa67ec7324b5"
      },
      "source": [
        "We define your device, model, and epochs; fill in the optimizer and loss function. For the optimizer, use an L2 weight of 0.01 and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c1295f8f-a1a0-4e99-bf6b-4c4aa4869305",
      "metadata": {
        "id": "c1295f8f-a1a0-4e99-bf6b-4c4aa4869305",
        "outputId": "43ac6e0d-47ce-40ec-ab38-85a53569a6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-66-912b0722ab1b>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-912b0722ab1b>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    optimizer = # Fill in\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "########### Code #############\n",
        "\n",
        "# device to train on\n",
        "device = 'cuda:0'\n",
        "# define your model\n",
        "model = PerovMLP(in_features=146).to(device)\n",
        "\n",
        "# define your optimizer\n",
        "optimizer = torch.op\n",
        "# define your loss function\n",
        "loss_fn = # Fill in\n",
        "\n",
        "# define number of epochs\n",
        "epochs = 250\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e226e1-08f1-4052-a400-04011ef30da5",
      "metadata": {
        "id": "30e226e1-08f1-4052-a400-04011ef30da5"
      },
      "source": [
        "Implement your training and validation loops here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb964f78-a81d-46d0-b11f-676f2c800476",
      "metadata": {
        "id": "bb964f78-a81d-46d0-b11f-676f2c800476"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "def train(model, dataloader, optimizer, loss_fn, device):\n",
        "\n",
        "    '''\n",
        "    A function train on the entire dataset for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): your model from before\n",
        "        dataloader (torch.utils.data.DataLoader): DataLoader object for the train data\n",
        "        optimizer (torch.optim.Optimizer(()): optimizer object to interface gradient calculation and optimization\n",
        "        device (str): Your device (usually 'cuda:0' for your GPU)\n",
        "\n",
        "    Returns:\n",
        "        float: loss averaged over all the batches\n",
        "    '''\n",
        "\n",
        "    epoch_loss = []\n",
        "    model.train() # Set model to training mode\n",
        "\n",
        "    for batch in dataloader:\n",
        "        X, y = batch\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # train your model on each batch here\n",
        "        y_pred = model(X)\n",
        "\n",
        "        ########### Code #############\n",
        "\n",
        "\n",
        "\n",
        "        ########### Code #############\n",
        "\n",
        "    return epoch_mean\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, dataloader, loss_fn, device):\n",
        "\n",
        "    '''\n",
        "    A function validate on the validation dataset for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): your model for before\n",
        "        dataloader (torch.utils.data.DataLoader): DataLoader object for the validation data\n",
        "        device (str): Your device (usually 'cuda:0' for your GPU)\n",
        "\n",
        "    Returns:\n",
        "        float: loss averaged over all the batches\n",
        "\n",
        "    '''\n",
        "\n",
        "    val_loss = []\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X, y = batch\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # validate your model on each batch here\n",
        "            y_pred = model(X)\n",
        "\n",
        "            ########### Code #############\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ########### Code #############\n",
        "\n",
        "\n",
        "    return epoch_mean\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cbd04ae-80bf-4502-bb8b-4fba5243f4cc",
      "metadata": {
        "id": "7cbd04ae-80bf-4502-bb8b-4fba5243f4cc"
      },
      "source": [
        "Train and validate your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089529c8-2252-4d10-9768-4f63b4942536",
      "metadata": {
        "id": "089529c8-2252-4d10-9768-4f63b4942536"
      },
      "outputs": [],
      "source": [
        "########### Code ###########\n",
        "val_loss_curve = []\n",
        "train_loss_curve = []\n",
        "\n",
        "def update(progress_bar, train_loss, val_loss):\n",
        "    progress_bar.set_postfix({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "progress_bar = tqdm(range(epochs)) # this wraps your iteration in a handy progress bar to track any metrics.\n",
        "\n",
        "for epoch in progress_bar:\n",
        "\n",
        "    # Train your model on training data\n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn=loss_fn, device=device)\n",
        "\n",
        "    # Validate your model on validation data\n",
        "    val_loss = validate(model, val_dataloader, loss_fn=loss_fn, device=device)\n",
        "\n",
        "    # Record train and loss performance\n",
        "    train_loss_curve.append(train_loss)\n",
        "    val_loss_curve.append(val_loss)\n",
        "\n",
        "    update(progress_bar, train_loss, val_loss)\n",
        "########### Code ###########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cde44d0-8004-4ef2-aaac-4a3d28814ef3",
      "metadata": {
        "id": "2cde44d0-8004-4ef2-aaac-4a3d28814ef3"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_curve, label=\"training\")\n",
        "plt.plot(val_loss_curve, label=\"validation\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "067cc3db-32e0-4780-ad73-acb0a6369062",
      "metadata": {
        "id": "067cc3db-32e0-4780-ad73-acb0a6369062"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
        "\n",
        "yhat_train = # Fill in\n",
        "yhat_val = # Fill in\n",
        "\n",
        "yhat_train = yhat_train.cpu().detach().numpy()\n",
        "yhat_val = yhat_train.cpu().detach().numpy()\n",
        "\n",
        "ax[0].scatter(yhat_train, y_subtrain, label='Train', alpha=0.5)\n",
        "ax[1].scatter(yhat_val, y_val, label='Test', alpha=0.5, c='orange')\n",
        "\n",
        "ax[0].set_ylabel(\"True $E_{hull}$ (eV/atom)\")\n",
        "ax[0].set_xlabel(\"Predicted $E_{hull}$ (eV/atom)\")\n",
        "ax[1].set_xlabel(\"Predicted $E_{hull}$ (eV/atom)\")\n",
        "ax[0].set_title('Train')\n",
        "ax[1].set_title('Validation')\n",
        "fig.suptitle('Multi-Layer Perceptron')\n",
        "\n",
        "print(\"Multi-Layer Perceptron training R^2 score: {:.2f}\".format(r2_score(y_subtrain, yhat_train)))\n",
        "print(\"Multi-Layer Perceptron validation R^2 score: {:.2f}\".format((r2_score(y_val, yhat_val))))\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2150e149-495e-4481-918f-e40d42ebd950",
      "metadata": {
        "id": "2150e149-495e-4481-918f-e40d42ebd950"
      },
      "source": [
        "## 2.4 (5 points) (grad) Calculate model size\n",
        "\n",
        "Calculate the total of number of parameters in your MLP model. What does the input hidden_layers_sizes = (256, 256, 256) mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099a3ec2-2914-417e-884d-fd27b2e95ebf",
      "metadata": {
        "id": "099a3ec2-2914-417e-884d-fd27b2e95ebf"
      },
      "outputs": [],
      "source": [
        "########## Answer ############\n",
        "\n",
        "\n",
        "########## Answer ############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f48e7a7b-5aed-4f4f-aa80-aa422fe342a4",
      "metadata": {
        "id": "f48e7a7b-5aed-4f4f-aa80-aa422fe342a4"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ac3c9d-c448-4225-8d99-b52aa7db2cf8",
      "metadata": {
        "id": "d8ac3c9d-c448-4225-8d99-b52aa7db2cf8"
      },
      "source": [
        "## 2.5 (5 points) Chemical Transferability of One-Hot Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d481954-cf06-402e-bef9-7ea27efe28da",
      "metadata": {
        "id": "7d481954-cf06-402e-bef9-7ea27efe28da"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "# Load the test dataset which contains elements not seen in the training data\n",
        "perov_test = pd.read_csv(\"perov_val.csv\")\n",
        "\n",
        "# Your code to preprocess data and predict on this test dataset, including a scatterplot of predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"MLP validation R^2 score: {:.2f}\".format(r2_score(y_test, yhat_test)))\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f124e48-f33f-4ff5-9e6c-1b67978f5e6c",
      "metadata": {
        "id": "6f124e48-f33f-4ff5-9e6c-1b67978f5e6c"
      },
      "source": [
        "Comment on your validation results and briefly explain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89a113ed-47f3-4fde-97ed-7a34dee2d31f",
      "metadata": {
        "id": "89a113ed-47f3-4fde-97ed-7a34dee2d31f"
      },
      "source": [
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8c0d983-bf74-4bb3-b91e-d060177fad2b",
      "metadata": {
        "id": "f8c0d983-bf74-4bb3-b91e-d060177fad2b"
      },
      "source": [
        "## 2.6 (10 points) (grad) Featurize perovskites with physical descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c429fa5c-65cf-4862-86b1-be8ebce5e74e",
      "metadata": {
        "id": "c429fa5c-65cf-4862-86b1-be8ebce5e74e"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "elements_pd = pd.read_csv(\"mendeleev.csv\")\n",
        "elements_pd = elements_pd.set_index('symbol')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7UcRjNMbOfZu",
      "metadata": {
        "id": "7UcRjNMbOfZu"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "# New dataloaders needed\n",
        "new_train_data = PerovskiteDataset(X_atom_train, y_atom_train)\n",
        "new_train_dataloader = DataLoader(new_train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "new_val_data = PerovskiteDataset(X_atom_val, y_atom_val)\n",
        "new_val_dataloader = DataLoader(new_val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Fill in the rest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Retrained MLP Training R^2 score: {:.2f}\".format(r2_score(y_atom_train, yhat_new_train)))\n",
        "print(\"Retrained MLP Validation R^2 score: {:.2f}\".format(r2_score(y_atom_val, yhat_new_val)))\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9d5a02-5361-4932-b358-12987ac0d827",
      "metadata": {
        "id": "0e9d5a02-5361-4932-b358-12987ac0d827"
      },
      "source": [
        "## 2.7 (10 points) (grad) Chemical transferability of Physical Descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a39363-5cde-400d-b81f-3b3170855ce3",
      "metadata": {
        "id": "c9a39363-5cde-400d-b81f-3b3170855ce3"
      },
      "outputs": [],
      "source": [
        "########### Code #############\n",
        "\n",
        "\n",
        "print(\"Retrained MLP Testing R^2 score: {:.2f}\".format(r2_score(y_test, yhat_test)))\n",
        "\n",
        "########### Code #############"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d2d7bf3-6acd-4ea7-a03e-da7182c09b7d",
      "metadata": {
        "id": "8d2d7bf3-6acd-4ea7-a03e-da7182c09b7d"
      },
      "source": [
        "Briefly comment on your validation and explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb74298-a8b9-4d3a-adc8-d091ca5481b9",
      "metadata": {
        "id": "adb74298-a8b9-4d3a-adc8-d091ca5481b9"
      },
      "source": [
        "Your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba63e8f-14b5-4d0b-ac2b-a9a07812b706",
      "metadata": {
        "id": "7ba63e8f-14b5-4d0b-ac2b-a9a07812b706"
      },
      "source": [
        "You've reached the end! Upon completing your pset, note any collaborators or assistance from AI tools in a cell below; and submit to Gradescope [here](https://www.gradescope.com/courses/1011324/assignments/6007173/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}